{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_8256\\2973693714.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__max_depth': None, 'classifier__min_samples_leaf': 2, 'classifier__min_samples_split': 5}\n",
      "Accuracy with Best Hyperparameters: 0.494791054713508\n",
      "Confusion Matrix:\n",
      "[[13698 11840]\n",
      " [13959 11569]]\n",
      "Applicant 1: Not Eligible for loan\n",
      "Applicant 2: Not Eligible for loan\n",
      "Applicant 3: Not Eligible for loan\n",
      "Applicant 4: Not Eligible for loan\n",
      "Applicant 5: Eligible for loan\n",
      "Applicant 6: Eligible for loan\n",
      "Applicant 7: Not Eligible for loan\n",
      "Applicant 8: Not Eligible for loan\n",
      "Applicant 9: Not Eligible for loan\n",
      "Applicant 10: Not Eligible for loan\n",
      "Applicant 11: Not Eligible for loan\n",
      "Applicant 12: Not Eligible for loan\n",
      "Applicant 13: Eligible for loan\n",
      "Applicant 14: Eligible for loan\n",
      "Applicant 15: Eligible for loan\n",
      "Applicant 16: Not Eligible for loan\n",
      "Applicant 17: Not Eligible for loan\n",
      "Applicant 18: Not Eligible for loan\n",
      "Applicant 19: Not Eligible for loan\n",
      "Applicant 20: Not Eligible for loan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load the data\n",
    "loan_data = pd.read_csv(\"newBankLoanApproval.csv\")\n",
    "applicants_data = pd.read_csv(\"newApplicants1.csv\")\n",
    "\n",
    "# Step 2: Separate features and target variable\n",
    "X = loan_data.drop(columns=['HasMortgage'])  # Features\n",
    "y = loan_data['HasMortgage']  # Target variable\n",
    "\n",
    "# Step 3: Define preprocessing steps for numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Step 4: Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Implement the Decision Tree algorithm within a pipeline\n",
    "decision_tree = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                                ('classifier', DecisionTreeClassifier())])\n",
    "\n",
    "# Step 7: Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'classifier__max_depth': [None, 5, 10, 15],  # Maximum depth of the tree\n",
    "    'classifier__min_samples_split': [2, 5, 10],  # Minimum samples required to split a node\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],  # Minimum samples required at each leaf node\n",
    "}\n",
    "\n",
    "# Step 8: Perform grid search\n",
    "grid_search = GridSearchCV(decision_tree, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Step 10: Evaluate the model with best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", accuracy)\n",
    "\n",
    "# Step 11: Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Step 12: Predict loan eligibility for applicants in newApplicants1.csv\n",
    "predictions = best_model.predict(applicants_data)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Applicant {i+1}: {'Eligible' if prediction == 1 else 'Not Eligible'} for loan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
