{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for BankLoanApproval\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"BankLoanApproval.csv\")\n",
    "\n",
    "# Mapping categorical values to numerical values\n",
    "education_mapping = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "employment_mapping = {\"Unemployed\": 0, \"Part-time\": 1, \"Full-time\": 2, \"Self-employed\": 3}\n",
    "marital_mapping = {\"Single\": 0, \"Married\": 1, \"Divorced\": 2}\n",
    "mortgage_mapping = {\"No\": 0, \"Yes\": 1}\n",
    "\n",
    "# Applying mappings to categorical columns\n",
    "df[\"Education\"] = df[\"Education\"].map(education_mapping)\n",
    "df[\"EmploymentType\"] = df[\"EmploymentType\"].map(employment_mapping)\n",
    "df[\"MaritalStatus\"] = df[\"MaritalStatus\"].map(marital_mapping)\n",
    "df[\"HasMortgage\"] = df[\"HasMortgage\"].map(mortgage_mapping)\n",
    "\n",
    "# Selecting required columns\n",
    "selected_columns = [\"Age\", \"Income\", \"LoanAmount\", \"CreditScore\", \"DTIRatio\", \"Education\", \"EmploymentType\", \"MaritalStatus\", \"HasMortgage\"]\n",
    "selected_df = df[selected_columns]\n",
    "\n",
    "# Saving to CSV\n",
    "selected_df.to_csv(\"newBankLoanApproval.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for NewApplicant\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"NewApplicants.csv\")\n",
    "\n",
    "# Mapping categorical values to numerical values\n",
    "education_mapping = {\"High School\": 0, \"Bachelor's\": 1, \"Master's\": 2, \"PhD\": 3}\n",
    "employment_mapping = {\"Unemployed\": 0, \"Part-time\": 1, \"Full-time\": 2, \"Self-employed\": 3}\n",
    "marital_mapping = {\"Single\": 0, \"Married\": 1, \"Divorced\": 2}\n",
    "mortgage_mapping = {\"No\": 0, \"Yes\": 1}\n",
    "\n",
    "# Applying mappings to categorical columns\n",
    "df[\"Education\"] = df[\"Education\"].map(education_mapping)\n",
    "df[\"EmploymentType\"] = df[\"EmploymentType\"].map(employment_mapping)\n",
    "df[\"MaritalStatus\"] = df[\"MaritalStatus\"].map(marital_mapping)\n",
    "df[\"HasMortgage\"] = df[\"HasMortgage\"].map(mortgage_mapping)\n",
    "\n",
    "# Selecting required columns\n",
    "selected_columns = [\"Age\", \"Income\", \"LoanAmount\", \"CreditScore\", \"DTIRatio\", \"Education\", \"EmploymentType\", \"MaritalStatus\", \"HasMortgage\"]\n",
    "selected_df = df[selected_columns]\n",
    "\n",
    "# Saving to CSV\n",
    "selected_df.to_csv(\"newApplicants1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_2044\\2538373242.py:1: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means:\n",
      "Age                   43.498059\n",
      "Income             82500.225585\n",
      "LoanAmount        127579.236559\n",
      "CreditScore          574.266125\n",
      "DTIRatio               0.500222\n",
      "Education              1.496269\n",
      "EmploymentType         1.498322\n",
      "MaritalStatus          1.000063\n",
      "HasMortgage            0.500002\n",
      "Name: mean, dtype: float64\n",
      "\n",
      "Standard Deviations:\n",
      "Age                  14.990304\n",
      "Income            38963.150663\n",
      "LoanAmount        70841.308245\n",
      "CreditScore         158.904496\n",
      "DTIRatio              0.230917\n",
      "Education             1.117208\n",
      "EmploymentType        1.117536\n",
      "MaritalStatus         0.816052\n",
      "HasMortgage           0.500001\n",
      "Name: std, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## calculate std dev and means for each columns\n",
    "import pandas as pd\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"newBankLoanApproval.csv\")\n",
    "\n",
    "# Check if every row has 9 columns\n",
    "def check_columns(row):\n",
    "    return len(row) == 9\n",
    "\n",
    "# Filter out rows with exactly 9 columns\n",
    "filtered_df = df[df.apply(check_columns, axis=1)]\n",
    "\n",
    "# Calculate mean and standard deviation for each column\n",
    "column_stats = filtered_df.describe().loc[['mean', 'std']]\n",
    "\n",
    "print(\"Means:\")\n",
    "print(column_stats.loc['mean'])\n",
    "print(\"\\nStandard Deviations:\")\n",
    "print(column_stats.loc['std'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"newBankLoanApproval.csv\")\n",
    "\n",
    "# Check if every row has 9 columns\n",
    "def check_columns(row):\n",
    "    return len(row) == 9\n",
    "\n",
    "# Filter out rows with exactly 9 columns\n",
    "filtered_df = df[df.apply(check_columns, axis=1)]\n",
    "\n",
    "# Calculate Z-scores for each row\n",
    "z_scores = filtered_df.apply(zscore, axis=1)\n",
    "\n",
    "# Save Z-scores to a new CSV file\n",
    "z_scores.to_csv(\"zscoreBankLoanApproval.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().values.any())\n",
    "# check if there is any null value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Read the data from CSV file\n",
    "df = pd.read_csv(\"zscoreBankLoanApproval.csv\")\n",
    "\n",
    "#Check if every row has 9 columns\n",
    "def check_columns(row):\n",
    "    return len(row) == 9\n",
    "\n",
    "#Apply the function to each row and check if all rows have 9 columns\n",
    "result = df.apply(check_columns, axis=1).all()\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "\n",
    "# Read the data from CSV file\n",
    "df = pd.read_csv(\"newApplicants1.csv\")\n",
    "\n",
    "# Check if every row has 9 columns\n",
    "def check_columns(row):\n",
    "    return len(row) == 9\n",
    "\n",
    "# Filter out rows with exactly 9 columns\n",
    "filtered_df = df[df.apply(check_columns, axis=1)]\n",
    "\n",
    "# Calculate Z-scores for each row\n",
    "z_scores = filtered_df.apply(zscore, axis=1)\n",
    "\n",
    "# Save Z-scores to a new CSV file\n",
    "z_scores.to_csv(\"zscoreNewApplicants.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applicant 1: Not Eligible for loan\n",
      "Applicant 2: Eligible for loan\n",
      "Applicant 3: Not Eligible for loan\n",
      "Applicant 4: Eligible for loan\n",
      "Applicant 5: Not Eligible for loan\n",
      "Applicant 6: Not Eligible for loan\n",
      "Applicant 7: Eligible for loan\n",
      "Applicant 8: Eligible for loan\n",
      "Applicant 9: Not Eligible for loan\n",
      "Applicant 10: Eligible for loan\n",
      "Applicant 11: Eligible for loan\n",
      "Applicant 12: Not Eligible for loan\n",
      "Applicant 13: Not Eligible for loan\n",
      "Applicant 14: Eligible for loan\n",
      "Applicant 15: Eligible for loan\n",
      "Applicant 16: Not Eligible for loan\n",
      "Applicant 17: Eligible for loan\n",
      "Applicant 18: Not Eligible for loan\n",
      "Applicant 19: Not Eligible for loan\n",
      "Applicant 20: Eligible for loan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 1: Load the data\n",
    "loan_data = pd.read_csv(\"newBankLoanApproval.csv\")\n",
    "applicants_data = pd.read_csv(\"newApplicants1.csv\")\n",
    "\n",
    "# Step 2: Separate features and target variable\n",
    "X = loan_data.drop(columns=['HasMortgage'])  # Features\n",
    "y = loan_data['HasMortgage']  # Target variable\n",
    "\n",
    "# Step 3: Define preprocessing steps for numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Step 4: Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Implement the KNN algorithm within a pipeline\n",
    "knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier(n_neighbors=5))])\n",
    "\n",
    "# Step 7: Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Predict loan eligibility for applicants in newApplicants1.csv\n",
    "predictions = knn.predict(applicants_data)\n",
    "\n",
    "# Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Applicant {i+1}: {'Eligible' if prediction == 1 else 'Not Eligible'} for loan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4998629224924607\n",
      "Confusion Matrix:\n",
      "[[12792 12746]\n",
      " [12794 12734]]\n",
      "Applicant 1: Not Eligible for loan\n",
      "Applicant 2: Eligible for loan\n",
      "Applicant 3: Not Eligible for loan\n",
      "Applicant 4: Not Eligible for loan\n",
      "Applicant 5: Not Eligible for loan\n",
      "Applicant 6: Not Eligible for loan\n",
      "Applicant 7: Eligible for loan\n",
      "Applicant 8: Eligible for loan\n",
      "Applicant 9: Eligible for loan\n",
      "Applicant 10: Eligible for loan\n",
      "Applicant 11: Eligible for loan\n",
      "Applicant 12: Not Eligible for loan\n",
      "Applicant 13: Not Eligible for loan\n",
      "Applicant 14: Eligible for loan\n",
      "Applicant 15: Eligible for loan\n",
      "Applicant 16: Not Eligible for loan\n",
      "Applicant 17: Eligible for loan\n",
      "Applicant 18: Not Eligible for loan\n",
      "Applicant 19: Not Eligible for loan\n",
      "Applicant 20: Eligible for loan\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load the data\n",
    "loan_data = pd.read_csv(\"newBankLoanApproval.csv\")\n",
    "applicants_data = pd.read_csv(\"newApplicants1.csv\")\n",
    "\n",
    "# Step 2: Separate features and target variable\n",
    "X = loan_data.drop(columns=['HasMortgage'])  # Features\n",
    "y = loan_data['HasMortgage']  # Target variable\n",
    "\n",
    "# Step 3: Define preprocessing steps for numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Step 4: Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 6: Implement the KNN algorithm within a pipeline\n",
    "knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier(n_neighbors=3))])\n",
    "\n",
    "# Step 7: Fit the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Step 8: Predict loan eligibility for applicants in newApplicants1.csv\n",
    "predictions = knn.predict(applicants_data)\n",
    "\n",
    "# Step 9: Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, knn.predict(X_test))\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Step 10: Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, knn.predict(X_test))\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Step 11: Print the predictions\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Applicant {i+1}: {'Eligible' if prediction == 1 else 'Not Eligible'} for loan\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'classifier__n_neighbors': 3}\n",
      "Accuracy with Best Hyperparameters: 1.0\n",
      "Confusion Matrix:\n",
      "[[76599]]\n",
      "Applicant 1: Not Eligible for loan\n",
      "Applicant 2: Not Eligible for loan\n",
      "Applicant 3: Not Eligible for loan\n",
      "Applicant 4: Not Eligible for loan\n",
      "Applicant 5: Not Eligible for loan\n",
      "Applicant 6: Not Eligible for loan\n",
      "Applicant 7: Not Eligible for loan\n",
      "Applicant 8: Not Eligible for loan\n",
      "Applicant 9: Not Eligible for loan\n",
      "Applicant 10: Not Eligible for loan\n",
      "Applicant 11: Not Eligible for loan\n",
      "Applicant 12: Not Eligible for loan\n",
      "Applicant 13: Not Eligible for loan\n",
      "Applicant 14: Not Eligible for loan\n",
      "Applicant 15: Not Eligible for loan\n",
      "Applicant 16: Not Eligible for loan\n",
      "Applicant 17: Not Eligible for loan\n",
      "Applicant 18: Not Eligible for loan\n",
      "Applicant 19: Not Eligible for loan\n",
      "Applicant 20: Not Eligible for loan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:386: UserWarning: A single label was found in 'y_true' and 'y_pred'. For the confusion matrix to have the correct shape, use the 'labels' parameter to pass all known labels.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Step 1: Load the data\n",
    "loan_data = pd.read_csv(\"zscoreBankLoanApproval.csv\")\n",
    "applicants_data = pd.read_csv(\"zscoreNewApplicants.csv\")\n",
    "\n",
    "# Step 2: Separate features and target variable\n",
    "X = loan_data.drop(columns=['HasMortgage'])  # Features\n",
    "y = loan_data['HasMortgage'] = (loan_data['HasMortgage'] > 0).astype(int) # Target variable\n",
    "\n",
    "# Step 3: Define preprocessing steps for numerical features\n",
    "numeric_features = X.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "numeric_transformer = Pipeline(steps=[('scaler', StandardScaler())])\n",
    "\n",
    "# Step 4: Combine preprocessing steps using ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features)\n",
    "    ])\n",
    "\n",
    "# Step 5: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Step 6: Implement the KNN algorithm within a pipeline\n",
    "knn = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('classifier', KNeighborsClassifier())])\n",
    "\n",
    "# Step 7: Define hyperparameters to tune\n",
    "param_grid = {\n",
    "    'classifier__n_neighbors': [3, 5, 7, 9, 11],  # Number of neighbors\n",
    "    # Add other hyperparameters to tune if needed\n",
    "}\n",
    "\n",
    "# Step 8: Perform grid search\n",
    "grid_search = GridSearchCV(knn, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 9: Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Step 10: Evaluate the model with best hyperparameters\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy with Best Hyperparameters:\", accuracy)\n",
    "\n",
    "# Step 11: Print confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n",
    "\n",
    "# Step 12: Predict loan eligibility for applicants in newApplicants1.csv\n",
    "predictions = best_model.predict(applicants_data)\n",
    "for i, prediction in enumerate(predictions):\n",
    "    print(f\"Applicant {i+1}: {'Eligible' if prediction == 1 else 'Not Eligible'} for loan\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
