{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will need to install tensorflow\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"BankLoanApproval.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['Education'] = features2['Education'].map(education_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['EmploymentType'] = features2['EmploymentType'].map(employment_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['MaritalStatus'] = features2['MaritalStatus'].map(marital_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:24: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['HasMortgage'] = features2['HasMortgage'].map(mortgage_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['HasDependents'] = features2['HasDependents'].map(dependent_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['LoanPurpose'] = features2['LoanPurpose'].map(loan_mapping)\n",
      "C:\\Users\\cheng\\AppData\\Local\\Temp\\ipykernel_7124\\2970098176.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  features2['HasCoSigner'] = features2['HasCoSigner'].map(cosigner_mapping)\n"
     ]
    }
   ],
   "source": [
    "education_mapping = {'High School': 0, \"Bachelor's\": 1, \"Master's\": 2, 'PhD': 3}\n",
    "employment_mapping = {'Unemployed': 0, 'Part-time': 1, 'Full-time': 2, 'Self-employed': 3}\n",
    "marital_mapping = {'Single': 0, 'Married': 1, 'Divorced': 2}\n",
    "mortgage_mapping = {'Yes': 1, 'No': 0}\n",
    "dependent_mapping ={'Yes': 1, 'No':0}\n",
    "loan_mapping ={'Education':0, 'Auto':1, 'Home':2, 'Other':3, 'Business':4}\n",
    "cosigner_mapping={'Yes': 1, 'No':0}\n",
    "\n",
    "# Select the specified columns\n",
    "features2 = df[[\"Age\", \"Income\", \"LoanAmount\", \"CreditScore\",\"InterestRate\",\"LoanTerm\",\"DTIRatio\", \n",
    "                       \"Education\", \"EmploymentType\", \"MaritalStatus\", \n",
    "                       \"HasMortgage\",\"HasDependents\",\"LoanPurpose\",\"HasCoSigner\"]]\n",
    "\n",
    "# Map the education column\n",
    "features2['Education'] = features2['Education'].map(education_mapping)\n",
    "\n",
    "# Map the employment column\n",
    "features2['EmploymentType'] = features2['EmploymentType'].map(employment_mapping)\n",
    "\n",
    "# Map the marital status column\n",
    "features2['MaritalStatus'] = features2['MaritalStatus'].map(marital_mapping)\n",
    "\n",
    "# Map the HasMortgage column\n",
    "features2['HasMortgage'] = features2['HasMortgage'].map(mortgage_mapping)\n",
    "\n",
    "features2['HasDependents'] = features2['HasDependents'].map(dependent_mapping)\n",
    "\n",
    "features2['LoanPurpose'] = features2['LoanPurpose'].map(loan_mapping)\n",
    "\n",
    "features2['HasCoSigner'] = features2['HasCoSigner'].map(cosigner_mapping)\n",
    "\n",
    "label = 'Default'\n",
    "\n",
    "\n",
    "X = features2\n",
    "y = df[label]\n",
    "\n",
    "X_train, X_test, y_train , y_test = train_test_split(X,y, test_size =0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 654us/step - accuracy: 0.8774 - loss: 0.3409 - val_accuracy: 0.8849 - val_loss: 0.3243\n",
      "Epoch 2/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 634us/step - accuracy: 0.8848 - loss: 0.3222 - val_accuracy: 0.8849 - val_loss: 0.3250\n",
      "Epoch 3/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 648us/step - accuracy: 0.8869 - loss: 0.3177 - val_accuracy: 0.8852 - val_loss: 0.3239\n",
      "Epoch 4/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 641us/step - accuracy: 0.8873 - loss: 0.3159 - val_accuracy: 0.8849 - val_loss: 0.3212\n",
      "Epoch 5/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 642us/step - accuracy: 0.8856 - loss: 0.3175 - val_accuracy: 0.8852 - val_loss: 0.3213\n",
      "Epoch 6/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 645us/step - accuracy: 0.8858 - loss: 0.3179 - val_accuracy: 0.8851 - val_loss: 0.3208\n",
      "Epoch 7/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 622us/step - accuracy: 0.8843 - loss: 0.3218 - val_accuracy: 0.8851 - val_loss: 0.3218\n",
      "Epoch 8/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 651us/step - accuracy: 0.8867 - loss: 0.3158 - val_accuracy: 0.8852 - val_loss: 0.3219\n",
      "Epoch 9/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 643us/step - accuracy: 0.8856 - loss: 0.3170 - val_accuracy: 0.8850 - val_loss: 0.3219\n",
      "Epoch 10/10\n",
      "\u001b[1m4469/4469\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 643us/step - accuracy: 0.8860 - loss: 0.3162 - val_accuracy: 0.8852 - val_loss: 0.3222\n",
      "\u001b[1m2394/2394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 426us/step - accuracy: 0.8840 - loss: 0.3220\n",
      "Test Loss: 0.3205743730068207\n",
      "Test Accuracy: 0.8850637674331665\n",
      "\u001b[1m2394/2394\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 396us/step\n",
      "\n",
      "Neural Network Evaluation:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.99      0.94     67658\n",
      "           1       0.58      0.06      0.11      8941\n",
      "\n",
      "    accuracy                           0.89     76599\n",
      "   macro avg       0.73      0.53      0.52     76599\n",
      "weighted avg       0.85      0.89      0.84     76599\n",
      "\n",
      "\n",
      "Neural Network Confusion Matrix:\n",
      "\n",
      "[[67270   388]\n",
      " [ 8416   525]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(64, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train_scaled, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "\n",
    "print(f'Test Loss: {test_loss}')\n",
    "print(f'Test Accuracy: {test_accuracy}')\n",
    "\n",
    "y_pred_prob = model.predict(X_test_scaled)\n",
    "\n",
    "# Convert probabilities to class labels using a threshold\n",
    "threshold = 0.5  # You can adjust this threshold as needed\n",
    "y_pred = (y_pred_prob > threshold).astype(int)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"\\nNeural Network Evaluation:\\n\") \n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"\\nNeural Network Confusion Matrix:\\n\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
